---
title: "inovick_OriginalHomeworkCode_05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#First, load the packages needed:
```{r}
library(curl)
library(ggplot2)
library(gridExtra)
library(lmodel2)
```
#Then, load the data using the curl command:
```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
```

#Challenge 1: Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).
```{r}
#Assigning variables:
homerange <- d$HomeRange_km2
bodymassf <- d$Body_mass_female_mean

#Using the lm function:
m <- lm(homerange ~ bodymassf)
m

#Creating a log linear regression:
logm<- lm(log(homerange) ~ log(bodymassf))
logm

logm$coefficients
#Slope= 1.036, intercept= -9.441
```

#Challenge 2: Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.

##First create the sample dataset:
```{r}
#code from https://towardsdatascience.com/bootstrap-regression-in-r-98bfe4ff5007

set.seed(2021) #A little confused about the set.seed function
## Diego: I may be wrong but I think the set.seed function makes that every time you run the code, the sample you take its the same so you obtain the same results.
n <- 1000
x <- rnorm(n)
y <- x + rnorm(n)
## Diego: I don't understand what the rnorm function does here

population.data <- as.data.frame(cbind(log(homerange), log(bodymassf)))

population.data <- as.data.frame(cbind(log(homerange), log(bodymassf)))
population.model <- lm(y ~ x, population.data)
summary(population.model)

sample.data <- population.data[sample(nrow(population.data), 20, replace = TRUE),]
sample.data

sample.model <- lm(y ~ x, data = sample.data)
summary(sample.model)

## Diego: Your coefficients for the "population.model" and "sample.model" models are exactly the same. I don't know if that should be happening. I think maybe it is because you are in both cases calling y ~ x, and you have defined y as rnorm(n) and x as y + rnorm(n), so you are calling the same data in both cases, which are random values from a normal distribution  
```
##Then use the bootstrap approach
```{r}
# Containers for the coefficients
sample_coef_intercept <- NULL
sample_coef_x1 <- NULL

for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = sample.data[sample(1:nrow(sample.data), nrow(sample.data), replace = TRUE), ]
  
  #Running the regression on these data
  model_bootstrap <- lm(y ~ x, data = sample_d)
  
  #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, model_bootstrap$coefficients[1])
  
  sample_coef_x1 <-
    c(sample_coef_x1, model_bootstrap$coefficients[2])
}
## Diego: Sorry I'm a bit confused with this code :/
## Diego: I think that for loop isn't necessary because you are not using "i" anywhere, so there is nothing repeating 1000 times. I think you have 1000 coefficients in "sample_coef_intercept" and "sample_coef_x1" because in "model_bootstrap" you use y~x, and as before, you are obtaining 1000 random values from the normal distribution. If you look at summary(model_bootstrap), you'll see that it's the same as the other models you've done before using y~x.

coefs <- rbind(sample_coef_intercept, sample_coef_x1)
```

##Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

#Combining these results in a table to have a clearer picture:
#Tried to add standard error but struggling
```{r}
means.boot = c(mean(sample_coef_intercept), mean(sample_coef_x1))
knitr::kable(round(
  cbind(
    population = coef(summary(population.model))[, 1],
    sample = coef(summary(sample.model))[, 1],
    bootstrap = means.boot),4), 
  "simple", caption = "Coefficients in different models")

confint(population.model)
pop.se <- function(population.data) sqrt(var(population.data)/length(population.data))
confint(sample.model)
samp.se <- function(sample.data) sqrt(var(sample.data)/length(sample.data))
a <-
  cbind(
    quantile(sample_coef_intercept, prob = 0.050),
    quantile(sample_coef_intercept, prob = 0.950))
b <-
  cbind(quantile(sample_coef_x1, prob = 0.050),
        quantile(sample_coef_x1, prob = 0.950))
## Diego: With this quantiles you are calculating the 90% CI

c <-
  round(cbind(
    population = confint(population.model),
    sample = confint(sample.model),
    boot = rbind(a, b)), 4)
colnames(c) <- c("5.0 %", "95.0 %",
                 "5.0 %", "95.0 %",
                 "5.0 %", "95.0 %")
knitr::kable(rbind(
  c('population',
    'population',
    'sample',
    'sample',
    'bootstrap',
    'bootstrap'),c))


## Diego: Good job building these tables! They look very tidy! I love them.
## Diego: In the first table, you can see that the coefficients are the same because of what I commented before!
```


##How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?
#Standard error should be higher for the sample models (I think), need help calculating standard error in this context because whatever I did didn't work.

##How does the latter compare to the 95% CI estimated from your entire dataset?
#It's similar but a little bit higher. Not a huge difference though.
